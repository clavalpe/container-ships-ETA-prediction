{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error \n",
    "from math import sqrt\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('../data/data.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación datasets de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 730163 entries, 0 to 730162\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   LATITUD        730163 non-null  float64\n",
      " 1   LONGITUD       730163 non-null  float64\n",
      " 2   VELOCIDAD      730163 non-null  float64\n",
      " 3   distance       730163 non-null  float64\n",
      " 4   Av.Speed       730163 non-null  float64\n",
      " 5   Time_Av.Speed  730163 non-null  float64\n",
      " 6   ChangeInSpeed  730163 non-null  float64\n",
      " 7   length         730163 non-null  int64  \n",
      " 8   width          730163 non-null  int64  \n",
      " 9   to_Arrive      730163 non-null  float64\n",
      "dtypes: float64(8), int64(2)\n",
      "memory usage: 55.7 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3031831 entries, 0 to 3031830\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   LATITUD        3031831 non-null  float64\n",
      " 1   LONGITUD       3031831 non-null  float64\n",
      " 2   VELOCIDAD      3031831 non-null  float64\n",
      " 3   distance       3031831 non-null  float64\n",
      " 4   Av.Speed       3031831 non-null  float64\n",
      " 5   Time_Av.Speed  3031831 non-null  float64\n",
      " 6   ChangeInSpeed  3031831 non-null  float64\n",
      " 7   length         3031831 non-null  int64  \n",
      " 8   width          3031831 non-null  int64  \n",
      " 9   to_Arrive      3031831 non-null  float64\n",
      "dtypes: float64(8), int64(2)\n",
      "memory usage: 231.3 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-2cab35440c5c>:32: FutureWarning: null_counts is deprecated. Use show_counts instead\n",
      "  df_data_train.info(null_counts=True)\n"
     ]
    }
   ],
   "source": [
    "# separar dataset de entrenamiento de dataset de test\n",
    "# Output: df_data_test, df_data_train\n",
    "\n",
    "\n",
    "# Paso 1: Listas que contiene rutas de entrenamiento y test\n",
    "size_data_test = round(len(data) * 0.2)\n",
    "\n",
    "data_test = []\n",
    "for i in range(0, size_data_test):\n",
    "    data_test.append(data[i])    \n",
    "\n",
    "    \n",
    "data_train = []\n",
    "for i in range(size_data_test, len(data)):\n",
    "    data_train.append(data[i]) \n",
    "    \n",
    "\n",
    "# Paso 2: Dataframe que contiene las rutas de entrenamiento y test\n",
    "data_test_routes = []\n",
    "for route in data_test:\n",
    "    data_test_routes.append(pd.DataFrame(route))\n",
    "    \n",
    "df_data_test = pd.concat(data_test_routes, ignore_index=True)\n",
    "df_data_test.info()\n",
    "\n",
    "\n",
    "data_train_routes = []\n",
    "for route in data_train:\n",
    "    data_train_routes.append(pd.DataFrame(route))\n",
    "    \n",
    "df_data_train = pd.concat(data_train_routes, ignore_index=True)\n",
    "df_data_train.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = df_data_train.rename(columns={'LATITUD': 'Latitude', 'LONGITUD': 'Longitude', 'VELOCIDAD':'Speed', 'distance':'Distance', 'length':'Length', 'width':'Width'})\n",
    "df_data_test = df_data_test.rename(columns={'LATITUD': 'Latitude', 'LONGITUD': 'Longitude', 'VELOCIDAD':'Speed', 'distance':'Distance', 'length':'Length', 'width':'Width'})\n",
    "\n",
    "df_data_train.to_Arrive = df_data_train.to_Arrive.round()\n",
    "\n",
    "# Selección de features\n",
    "X_test = df_data_test[['Longitude', 'Latitude', 'Speed', 'Length', 'Width']] \n",
    "y_test = df_data_test[\"to_Arrive\"].values.reshape(-1, 1)\n",
    "\n",
    "X_train = df_data_train[['Longitude', 'Latitude', 'Speed', 'Length', 'Width']]\n",
    "y_train = df_data_train[\"to_Arrive\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "y_train = y_scaler.fit_transform(y_train)\n",
    "\n",
    "X_test = X_scaler.fit_transform(X_test)\n",
    "y_test = y_scaler.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree regresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=5)\n",
    "tree.fit(X_train,y_train)          \n",
    "y_train_hat = tree.predict(X_train)\n",
    "y_test_hat = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.47586265826735696\n",
      "Test 0.4623609589669596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"Train\", r2_score(y_train, y_train_hat))\n",
    "print(\"Test\", r2_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 31.041900372006168\n"
     ]
    }
   ],
   "source": [
    "y_test = y_scaler.inverse_transform(y_test)\n",
    "y_test_hat = y_scaler.inverse_transform(y_test_hat)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_test_hat)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2227.469164091675\n"
     ]
    }
   ],
   "source": [
    "mse =mean_squared_error(y_test, y_test_hat)\n",
    "print(\"Mean Squared Error:\",mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 47.19607149002632\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.88 TiB for an array with shape (730163, 730163) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7ef423ffb259>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test_hat\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.88 TiB for an array with shape (730163, 730163) and data type float64"
     ]
    }
   ],
   "source": [
    "error = y_test_hat - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns, numpy as np\n",
    "sns.set_theme(); np.random.seed(0)\n",
    "ax = sns.distplot(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('models/dtree_weather_model.sav', 'wb'))\n",
    "pickle.dump(X_scaler, open('models/dtree_weather_X_scaler.sav', 'wb'))\n",
    "pickle.dump(y_scaler, open('models/dtree_weather_y_scaler.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
